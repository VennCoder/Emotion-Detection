{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b20415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary:\n",
      "emotion\n",
      "calm        192\n",
      "happy       192\n",
      "sad         192\n",
      "angry       192\n",
      "fear        192\n",
      "disgust     192\n",
      "surprise    192\n",
      "neutral      96\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\anaconda3\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1012\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1418 - loss: 4.5259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.1437 - loss: 4.4573 - val_accuracy: 0.2917 - val_loss: 1.9133\n",
      "Epoch 2/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2471 - loss: 1.9336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2472 - loss: 1.9327 - val_accuracy: 0.2986 - val_loss: 1.8402\n",
      "Epoch 3/200\n",
      "\u001b[1m10/18\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2850 - loss: 1.8224 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2912 - loss: 1.8133 - val_accuracy: 0.2674 - val_loss: 1.7575\n",
      "Epoch 4/200\n",
      "\u001b[1m10/18\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3050 - loss: 1.7664 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3113 - loss: 1.7571 - val_accuracy: 0.3646 - val_loss: 1.7192\n",
      "Epoch 5/200\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3559 - loss: 1.6728 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3517 - loss: 1.6711 - val_accuracy: 0.3785 - val_loss: 1.7088\n",
      "Epoch 6/200\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3412 - loss: 1.6903 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3451 - loss: 1.6769 - val_accuracy: 0.3819 - val_loss: 1.6370\n",
      "Epoch 7/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3969 - loss: 1.5629 - val_accuracy: 0.3750 - val_loss: 1.6374\n",
      "Epoch 8/200\n",
      "\u001b[1m10/18\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3881 - loss: 1.6345 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4057 - loss: 1.5970 - val_accuracy: 0.4167 - val_loss: 1.5666\n",
      "Epoch 9/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4163 - loss: 1.5310 - val_accuracy: 0.4201 - val_loss: 1.5844\n",
      "Epoch 10/200\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4771 - loss: 1.4402 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4703 - loss: 1.4516 - val_accuracy: 0.4618 - val_loss: 1.5368\n",
      "Epoch 11/200\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4316 - loss: 1.4741 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4454 - loss: 1.4622 - val_accuracy: 0.4479 - val_loss: 1.5304\n",
      "Epoch 12/200\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4625 - loss: 1.4000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4582 - loss: 1.4162 - val_accuracy: 0.4340 - val_loss: 1.5108\n",
      "Epoch 13/200\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5141 - loss: 1.3552 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5124 - loss: 1.3559 - val_accuracy: 0.4479 - val_loss: 1.4614\n",
      "Epoch 14/200\n",
      "\u001b[1m10/18\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4842 - loss: 1.3409 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4950 - loss: 1.3309 - val_accuracy: 0.4861 - val_loss: 1.4491\n",
      "Epoch 15/200\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5420 - loss: 1.2340 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5437 - loss: 1.2372 - val_accuracy: 0.5069 - val_loss: 1.4487\n",
      "Epoch 16/200\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5508 - loss: 1.1974 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5512 - loss: 1.2011 - val_accuracy: 0.4444 - val_loss: 1.4435\n",
      "Epoch 17/200\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5551 - loss: 1.1895 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5515 - loss: 1.2093 - val_accuracy: 0.5278 - val_loss: 1.4120\n",
      "Epoch 18/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5655 - loss: 1.2473 - val_accuracy: 0.5139 - val_loss: 1.4708\n",
      "Epoch 19/200\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5726 - loss: 1.1176 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5766 - loss: 1.1185 - val_accuracy: 0.5486 - val_loss: 1.3735\n",
      "Epoch 20/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6189 - loss: 1.0654 - val_accuracy: 0.5104 - val_loss: 1.4609\n",
      "Epoch 21/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5809 - loss: 1.0907 - val_accuracy: 0.5417 - val_loss: 1.3827\n",
      "Epoch 22/200\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6129 - loss: 1.0533 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6143 - loss: 1.0535 - val_accuracy: 0.5590 - val_loss: 1.3283\n",
      "Epoch 23/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6527 - loss: 0.9731 - val_accuracy: 0.5556 - val_loss: 1.3567\n",
      "Epoch 24/200\n",
      "\u001b[1m14/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6917 - loss: 0.8505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6845 - loss: 0.8675 - val_accuracy: 0.5938 - val_loss: 1.3080\n",
      "Epoch 25/200\n",
      "\u001b[1m10/18\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6959 - loss: 0.8762 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6936 - loss: 0.8808 - val_accuracy: 0.5833 - val_loss: 1.2706\n",
      "Epoch 26/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7059 - loss: 0.8333 - val_accuracy: 0.5799 - val_loss: 1.3862\n",
      "Epoch 27/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6891 - loss: 0.8307 - val_accuracy: 0.5764 - val_loss: 1.4336\n",
      "Epoch 28/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7379 - loss: 0.7287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7371 - loss: 0.7302 - val_accuracy: 0.6042 - val_loss: 1.2631\n",
      "Epoch 29/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7306 - loss: 0.7629 - val_accuracy: 0.5694 - val_loss: 1.3977\n",
      "Epoch 30/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7447 - loss: 0.6882 - val_accuracy: 0.6319 - val_loss: 1.3432\n",
      "Epoch 31/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7833 - loss: 0.6413 - val_accuracy: 0.5833 - val_loss: 1.3625\n",
      "Epoch 32/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7855 - loss: 0.6038 - val_accuracy: 0.6042 - val_loss: 1.3483\n",
      "Epoch 33/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7748 - loss: 0.6074 - val_accuracy: 0.5799 - val_loss: 1.3910\n",
      "Epoch 34/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8337 - loss: 0.5234 - val_accuracy: 0.6215 - val_loss: 1.2823\n",
      "Epoch 35/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8264 - loss: 0.5344 - val_accuracy: 0.6285 - val_loss: 1.3397\n",
      "Epoch 36/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8150 - loss: 0.5381 - val_accuracy: 0.6181 - val_loss: 1.4504\n",
      "Epoch 37/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8201 - loss: 0.4829 - val_accuracy: 0.6076 - val_loss: 1.4203\n",
      "Epoch 38/200\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8214 - loss: 0.5082 - val_accuracy: 0.6458 - val_loss: 1.4376\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.68      0.74      0.71        38\n",
      "        calm       0.60      0.84      0.70        38\n",
      "     disgust       0.65      0.45      0.53        38\n",
      "        fear       0.62      0.72      0.67        39\n",
      "       happy       0.72      0.46      0.56        39\n",
      "     neutral       0.42      0.26      0.32        19\n",
      "         sad       0.44      0.45      0.44        38\n",
      "    surprise       0.62      0.74      0.67        39\n",
      "\n",
      "    accuracy                           0.60       288\n",
      "   macro avg       0.59      0.58      0.58       288\n",
      "weighted avg       0.61      0.60      0.59       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import librosa\n",
    "import joblib\n",
    "from librosa.feature import spectral_contrast, tonnetz\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "class AdvancedVoiceEmotionDetector:\n",
    "    def __init__(self, dataset_path):\n",
    "        \"\"\"\n",
    "        Initialize voice emotion detection system.\n",
    "        \n",
    "        Args:\n",
    "            dataset_path (str): Path to RAVDESS dataset\n",
    "        \"\"\"\n",
    "        self.dataset_path = dataset_path\n",
    "        self.emotion_map = {\n",
    "            1: 'neutral', 2: 'calm', 3: 'happy', \n",
    "            4: 'sad', 5: 'angry', 6: 'fear', \n",
    "            7: 'disgust', 8: 'surprise'\n",
    "        }\n",
    "    \n",
    "    def create_metadata_dataframe(self):\n",
    "        \"\"\"\n",
    "        Create metadata DataFrame from RAVDESS dataset.\n",
    "        \n",
    "        Returns:\n",
    "            pandas.DataFrame: Metadata for all audio files\n",
    "        \"\"\"\n",
    "        emotion = []\n",
    "        gender = []\n",
    "        actor = []\n",
    "        file_path = []\n",
    "        \n",
    "        actor_folders = [f for f in os.listdir(self.dataset_path) if os.path.isdir(os.path.join(self.dataset_path, f))]\n",
    "        \n",
    "        for actor_folder in actor_folders:\n",
    "            actor_path = os.path.join(self.dataset_path, actor_folder)\n",
    "            filenames = os.listdir(actor_path)\n",
    "            \n",
    "            for filename in filenames:\n",
    "                parts = filename.split('.')[0].split('-')\n",
    "                emotion_code = int(parts[2])\n",
    "                emotion.append(emotion_code)\n",
    "                \n",
    "                actor_number = int(parts[6])\n",
    "                actor.append(actor_number)\n",
    "                gender.append('female' if actor_number % 2 == 0 else 'male')\n",
    "                \n",
    "                full_path = os.path.join(actor_path, filename)\n",
    "                file_path.append(full_path)\n",
    "        \n",
    "        audio_df = pd.DataFrame({\n",
    "            'emotion_code': emotion,\n",
    "            'emotion': [self.emotion_map[code] for code in emotion],\n",
    "            'gender': gender,\n",
    "            'actor': actor,\n",
    "            'path': file_path\n",
    "        })\n",
    "        \n",
    "        return audio_df\n",
    "    \n",
    "    def extract_audio_features(self, file_path, max_pad_length=100):\n",
    "        \"\"\"\n",
    "        Extract advanced audio features.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to audio file\n",
    "            max_pad_length (int): Max length for feature padding\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Processed audio features or None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            audio, sample_rate = librosa.load(file_path, duration=5.0)\n",
    "\n",
    "            # Extract Features\n",
    "            mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "            chroma = librosa.feature.chroma_stft(y=audio, sr=sample_rate)\n",
    "            mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
    "            zcr = librosa.feature.zero_crossing_rate(y=audio)\n",
    "            spectral_contrast_features = spectral_contrast(y=audio, sr=sample_rate)\n",
    "            tonnetz_features = tonnetz(y=audio, sr=sample_rate)\n",
    "\n",
    "            # Combine features\n",
    "            features = np.concatenate([\n",
    "                np.mean(mfccs, axis=1),\n",
    "                np.mean(chroma, axis=1),\n",
    "                np.mean(mel, axis=1),\n",
    "                [np.mean(zcr)],\n",
    "                np.mean(spectral_contrast_features, axis=1),\n",
    "                np.mean(tonnetz_features, axis=1)\n",
    "            ])\n",
    "\n",
    "            # Pad/truncate to fixed size\n",
    "            if len(features) > max_pad_length:\n",
    "                features = features[:max_pad_length]\n",
    "            else:\n",
    "                features = np.pad(features, (0, max_pad_length - len(features)), 'constant')\n",
    "\n",
    "            return features\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    \n",
    "    def prepare_dataset(self, audio_df):\n",
    "        \"\"\"\n",
    "        Prepare dataset for machine learning.\n",
    "        \n",
    "        Args:\n",
    "            audio_df (pandas.DataFrame): Metadata DataFrame\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Features, labels, and label encoder\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        labels = []\n",
    "        \n",
    "        for _, row in audio_df.iterrows():\n",
    "            feature = self.extract_audio_features(row['path'])\n",
    "            if feature is not None:\n",
    "                features.append(feature)\n",
    "                labels.append(row['emotion'])\n",
    "        \n",
    "        X = np.array(features)\n",
    "        y = np.array(labels)\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "        \n",
    "        return X, y_encoded, label_encoder\n",
    "    \n",
    "    def create_model(self, input_shape, num_classes):\n",
    "        \"\"\"\n",
    "        Create a CNN-based model for voice emotion detection.\n",
    "        \n",
    "        Args:\n",
    "            input_shape (tuple): Shape of input features\n",
    "            num_classes (int): Number of emotion classes\n",
    "        \n",
    "        Returns:\n",
    "            tensorflow.keras.Model: Compiled CNN model\n",
    "        \"\"\"\n",
    "        model = Sequential([\n",
    "            Conv1D(64, kernel_size=3, activation='relu', input_shape=(input_shape[0], 1), kernel_regularizer=l2(0.01)),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "\n",
    "            Conv1D(128, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "            Dropout(0.5),\n",
    "            \n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def scheduler(self, epoch, lr):\n",
    "        \"\"\"Learning rate scheduler.\"\"\"\n",
    "        if epoch < 100:\n",
    "            return lr\n",
    "        elif epoch < 200:\n",
    "            return lr * 0.5\n",
    "        else:\n",
    "            return lr * 0.1\n",
    "\n",
    "    def train_and_evaluate(self, X, y, label_encoder, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Train and evaluate the CNN-based emotion detection model.\n",
    "        \n",
    "        Args:\n",
    "            X (numpy.ndarray): Input features\n",
    "            y (numpy.ndarray): Label data\n",
    "            label_encoder (sklearn.preprocessing.LabelEncoder): Label encoder\n",
    "            test_size (float): Test dataset proportion\n",
    "        \n",
    "        Returns:\n",
    "            tensorflow.keras.Model: Trained model\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        # Reshape for CNN\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "        X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "        model = self.create_model(input_shape=(X_train.shape[1], 1), num_classes=len(np.unique(y)))\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        model_checkpoint = ModelCheckpoint('best_voice_emotion_model.h5', save_best_only=True)\n",
    "\n",
    "        # Learning Rate Scheduler\n",
    "        lr_scheduler = LearningRateScheduler(self.scheduler)\n",
    "\n",
    "        # Train model with increased epochs and batch size\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=300,  # Increased from 200 to 300\n",
    "            batch_size=128,  # Increased from 64 to 128\n",
    "            callbacks=[early_stopping, model_checkpoint, lr_scheduler],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        self.evaluate_model(model, X_test, y_test, label_encoder)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def evaluate_model(self, model, X_test, y_test, label_encoder):\n",
    "        \"\"\"\n",
    "        Evaluate model performance.\n",
    "        \n",
    "        Args:\n",
    "            model (tensorflow.keras.Model): Trained model\n",
    "            X_test (numpy.ndarray): Test features\n",
    "            y_test (numpy.ndarray): Test labels\n",
    "            label_encoder (sklearn.preprocessing.LabelEncoder): Label encoder\n",
    "        \"\"\"\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        from sklearn.metrics import classification_report\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"\n",
    "        Run the complete voice emotion detection pipeline.\n",
    "        \"\"\"\n",
    "        audio_df = self.create_metadata_dataframe()\n",
    "        \n",
    "        print(\"Dataset Summary:\")\n",
    "        print(audio_df['emotion'].value_counts())\n",
    "\n",
    "        X, y, label_encoder = self.prepare_dataset(audio_df)\n",
    "\n",
    "        model = self.train_and_evaluate(X, y, label_encoder)\n",
    "\n",
    "        model.save('final_voice_emotion_model.h5')\n",
    "        joblib.dump(label_encoder, 'voice_emotion_label_encoder.pkl')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset_path = r'C:\\Users\\aksha\\Downloads\\RAVDESS\\audio_speech_actors_01-24'\n",
    "    detector = AdvancedVoiceEmotionDetector(dataset_path)\n",
    "    detector.run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0535ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
